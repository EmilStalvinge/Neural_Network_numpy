# Neural_Network_numpy
A Neural network from scratch with numpy. 



\section{Mathematical exercises}

The chosen loss function Li for a multi-output classification problem is the cross-entropy loss which, for
numerical issues when z  0, is computed together with the softmax function. The cost J, for an M-class problem, is computed by summing the loss Li over all the training points xi

<img src="https://render.githubusercontent.com/render/math?math=L_i = ln(\sum_{l=1}^M e^{z_{il}}) - \sum_{m=1}^M \tilde{y}_{im}z_{im}">

<img src="https://render.githubusercontent.com/render/math?math=e^{i \pi} = -1">

